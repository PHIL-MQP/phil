{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to do the calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The first step is to let the IMU sit at rest for $T_{init}$ seconds. This interval is derived from the Allen Variance metnhod.\n",
    " - Also during this initial time interval, measure the average gyro readings in each axis: $\\textbf{b}^g$\n",
    " - Let the IMU sit at some orientation for 4 seconds, then move it to some other orientation. Repeat this between 36 and 50 times.\n",
    " - Iterate over each gyroscope readings and subtract the bias $\\text{b}^g$\n",
    " - Compute the magnitude of the variance $\\varsigma_{init}$ for the accelerometer data over the $T_{init}$. To do this, you iterate over each accelerometer reading during $T_{init}$ and compute the sample variance. This is the average of the variance for each point: $var(a) = (a-\\mathbb{E}[a])^2$. Do this for each axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick code example of this part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_value:  1.03333333333\n",
      "sample variance: 0.0322222222222\n"
     ]
    }
   ],
   "source": [
    "x = [1.1, 1.2, 0.9, 0.9, 1.3, 0.8]\n",
    "expected_value = np.mean(x)\n",
    "print(\"expected_value: \", expected_value)\n",
    "sample_variance = np.mean((x - expected_value)**2)\n",
    "print(\"sample variance:\", sample_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Iterate over a bunch of thresholds and compute how good each one is at calibrating the data. This is what the loop in Algorithm 1 refers to.\n",
    "   - Set the threshold you're testing to $threshold = i * \\varsigma_{init}$\n",
    "   - Compute the regions of static/dynamic using that threshold\n",
    "     - Iterate over each window of $t_{wait}$ size in the collected data and compute the sample variance (same as above) and compare to the threshold\n",
    "     - If it's greater, the you classify as dynamics, otherwise as static\n",
    "     - The output will be like the black line in Figure 3\n",
    "   - Do the LM optimization (magic call the Eigen).\n",
    "     - For this LM, we need to provide a functor that has `int operator()(const Eigen::VectorXf &x, Eigen::VectorXf &fvec) const` and `int df(const Eigen::VectorXf &x, Eigen::MatrixXf &fjac) const`. For `operator()` it should fill `fvec` with the values of the equation $e_k={\\lVert g\\rVert}^2 - {\\lVert T^aK^a(a_k^S+b^a)\\rVert}^2$, where ${\\lVert g\\rVert}^2 = 9.8$. For `df`, you fill `fjac` with each error term $\\frac{\\partial e_1}{\\partial \\theta^{acc}}, \\dots, \\frac{\\partial e_k}{\\partial \\theta^{acc}}$.\n",
    "      - Compute the residuals for the final optimized parameters\n",
    "      - Save (residuals, params, threshold, intervals) if they're the best ones so far\n",
    " - Calibrate the accelerometer $a^o = T^aK^a(a^S+b^a)$\n",
    " - Calibrate the gyroscope using another LM. This time in `int operator()` you fill `fvec` with $\\lVert(u_{a,k} - u_{g,k})\\rVert$ and also the partials into `fjac`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Jacobians\n",
    "\n",
    "Look in `docs/IMU_calibration.pdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the accuacy of numerical derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five-point approximations\n",
      "[[ 0.192     ]\n",
      " [-0.024     ]\n",
      " [ 0.158     ]\n",
      " [-0.04800001]\n",
      " [-1.24480035]\n",
      " [-0.0042    ]\n",
      " [-0.24      ]\n",
      " [-1.556     ]\n",
      " [-0.042     ]]\n"
     ]
    }
   ],
   "source": [
    "def func(theta_acc):\n",
    "    T = np.array([[1, -theta_acc[0], theta_acc[1]],[0, 1, -theta_acc[2]],[0,0,1]])\n",
    "    K = np.array([[theta_acc[3],0,0],[0,theta_acc[4],0],[0,0,theta_acc[5]]])\n",
    "    b = np.array([[theta_acc[6]],[theta_acc[7]],[theta_acc[8]]])\n",
    "    return 1 - np.linalg.norm(T@K@(a_i + b))**2\n",
    "\n",
    "def five_point_approximation(func, theta_acc, h):\n",
    "    N = theta_acc.shape[1]\n",
    "    partials = np.ndarray((N,1))\n",
    "    for partial_idx in range(N):\n",
    "        hs = np.array([-2*h, -h, h, 2*h])\n",
    "        nodes = np.repeat(theta_acc, 4, axis=0)\n",
    "        nodes[:,partial_idx] += hs\n",
    "        five_point_approx = 1/(12*h)*(func(nodes[0]) - 8*func(nodes[1]) + 8*func(nodes[2]) - func(nodes[3]))\n",
    "        partials[partial_idx] = five_point_approx\n",
    "    return partials\n",
    "\n",
    "\n",
    "# theta_acc = [a_yz, a_zy, a_zx, s_x_a, s_y_a, s_z_a, b_x_a, b_y_a, b_z_a]\n",
    "theta_acc = np.array([[0.1, 0, 0.1, 1, 1, 1, 0, 0.1, 0]], dtype=np.float32)\n",
    "a_i = np.array([[0.2], [0.7], [0.1]])\n",
    "h = 0.1\n",
    "\n",
    "print(\"five-point approximations\")\n",
    "print(five_point_approximation(func, theta_acc, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hs = np.array([-2*h, -h, h, 2*h])\n",
    "nodes = np.repeat(theta_acc, 4, axis=0)\n",
    "nodes[:,0] += hsReferences:\n",
    "\n",
    " - https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf\n",
    " - http://eigen.tuxfamily.org/bz_attachmentbase/attachment.cgi?id=395\n",
    " - https://medium.com/@sarvagya.vaish/levenberg-marquardt-optimization-part-1-981f5777b1d7\n",
    " - https://medium.com/@sarvagya.vaish/levenberg-marquardt-optimization-part-2-5a71f7db27a0\n",
    " - https://github.com/SarvagyaVaish/Eigen-Levenberg-Marquardt-Optimization/blob/master/main.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = \"recorded_sensor_data/imu_calibration_11_14_20-00-00/imu_calibration_data_11_14.csv\"\n",
    "reader = csv.reader(open(data_filename, 'r'))\n",
    "\n",
    "next(reader) # skip header\n",
    "data = []\n",
    "for row in reader:\n",
    "    data.append([float(x) for x in row])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterate over the Tinit period to compute the gyro biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyro_biases: [ 0.0654159   0.13007117  0.08329117]\n"
     ]
    }
   ],
   "source": [
    "Tinit = 4\n",
    "samples_per_second = 100\n",
    "Tinit_idx = 4 * samples_per_second\n",
    "init_data = data[:Tinit_idx]\n",
    "remaining_data = data[Tinit_idx:]\n",
    "gyro_biases = np.mean(init_data, axis=0)[3:6]\n",
    "print(\"gyro_biases:\", gyro_biases)\n",
    "sample_variance = np.var(init_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_static_intervals(threshold, data, t_wait, sample_per_second):\n",
    "    window_size = sample_per_second * t_wait\n",
    "    if window_size % 2 == 0:\n",
    "        window_size -= 1\n",
    "    data_array_size = len(data)\n",
    "    static_indicators = []\n",
    "    temp_pair = [-1, -1]\n",
    "    previous_static_indicator = 1\n",
    "    for i in range(data_array_size - window_size):\n",
    "#     for i in range(50,51):\n",
    "        window_data = data[i:i+window_size]\n",
    "#         plt.figure(figsize=(15,15))\n",
    "#         plt.title(\"init data\")\n",
    "#         plt.plot(window_data[:,0], label=\"accel x\")\n",
    "#         plt.plot(window_data[:,1], label=\"accel y\")\n",
    "#         plt.plot(window_data[:,2], label=\"accel z\")\n",
    "\n",
    "        \n",
    "        variance = np.linalg.norm(np.var(window_data[:, :3], axis = 0))**2\n",
    "        \n",
    "        #end of a static interval\n",
    "        if (variance > threshold) and (previous_static_indicator == 0):\n",
    "            temp_pair[1] = i + window_size // 2\n",
    "            static_indicators.append(temp_pair)\n",
    "            temp_pair = [-1, -1]\n",
    "        #start of a static intervals\n",
    "        elif (variance < threshold) and (previous_static_indicator == 1):\n",
    "            temp_pair[0] = i + window_size // 2\n",
    "        \n",
    "        previous_static_indicator = 1 if (variance > threshold) else 0\n",
    "        \n",
    "    if previous_static_indicator == 0:\n",
    "        temp_pair[1] = data_array_size - window_size // 2 - 1\n",
    "        static_indicators.append(temp_pair)\n",
    "    \n",
    "#     plt.show()\n",
    "    return static_indicators\n",
    "def get_static_points(threshold, data, t_wait, sample_per_second):\n",
    "    window_size = sample_per_second * t_wait\n",
    "    if window_size % 2 == 0:\n",
    "        window_size -= 1\n",
    "    data_array_size = len(data)\n",
    "    static_indicators = []\n",
    "    temp_pair = [-1, -1]\n",
    "    previous_static_indicator = 1\n",
    "    for i in range(data_array_size - window_size):\n",
    "#     for i in range(50,51):\n",
    "        window_data = data[i:i+window_size]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_init: 1.0761588803e-05\n",
      "t 1.15811793564e-10\n",
      "[[1487, 1497], [3763, 3829], [6949, 7019]]\n",
      "t 2.31623587128e-10\n",
      "[[1483, 1501], [2556, 2677], [3760, 3829], [6940, 7021]]\n",
      "t 3.47435380691e-10\n",
      "[[1482, 1501], [2554, 2678], [3753, 3829], [6148, 6150], [6225, 6239], [6247, 6257], [6643, 6644], [6939, 7021]]\n",
      "t 4.63247174255e-10\n",
      "[[1482, 1501], [2554, 2678], [3751, 3829], [6145, 6259], [6602, 6647], [6936, 7021]]\n",
      "t 5.79058967819e-10\n",
      "[[1482, 1501], [2554, 2686], [3749, 3830], [6145, 6260], [6600, 6648], [6935, 7021]]\n",
      "t 6.94870761383e-10\n",
      "[[1481, 1501], [2554, 2689], [3748, 3830], [6145, 6260], [6593, 6649], [6935, 7021]]\n",
      "t 8.10682554947e-10\n",
      "[[1481, 1501], [2554, 2689], [3747, 3830], [5836, 5840], [5841, 5861], [6145, 6260], [6591, 6650], [6935, 7023]]\n",
      "t 9.2649434851e-10\n",
      "[[1481, 1501], [2554, 2690], [3747, 3830], [5819, 5862], [6145, 6261], [6589, 6651], [6935, 7024]]\n",
      "t 1.04230614207e-09\n",
      "[[190, 193], [1481, 1501], [2554, 2690], [3747, 3830], [5812, 5864], [6145, 6261], [6585, 6652], [6935, 7029]]\n",
      "t 1.15811793564e-09\n",
      "[[189, 194], [1481, 1501], [2554, 2691], [3747, 3830], [5811, 5864], [6145, 6261], [6584, 6652], [6935, 7030]]\n",
      "t 1.2739297292e-09\n",
      "[[189, 198], [1481, 1501], [2554, 2691], [3747, 3831], [5810, 5865], [6145, 6261], [6580, 6653], [6935, 7031]]\n",
      "t 1.38974152277e-09\n",
      "[[188, 198], [1481, 1501], [2554, 2691], [3747, 3832], [5810, 5866], [6145, 6261], [6578, 6654], [6935, 7031]]\n",
      "t 1.50555331633e-09\n",
      "[[188, 198], [1481, 1501], [2554, 2691], [3747, 3849], [5810, 5866], [6145, 6262], [6578, 6655], [6935, 7031]]\n",
      "t 1.62136510989e-09\n",
      "[[187, 199], [1481, 1501], [2554, 2692], [3030, 3034], [3041, 3050], [3052, 3053], [3058, 3061], [3747, 3866], [5810, 5866], [6145, 6262], [6575, 6655], [6935, 7032]]\n",
      "t 1.73717690346e-09\n",
      "[[187, 199], [1481, 1501], [2554, 2692], [3025, 3079], [3747, 3880], [5809, 5866], [6145, 6262], [6574, 6656], [6935, 7032]]\n",
      "t 1.85298869702e-09\n",
      "[[187, 199], [1481, 1501], [2554, 2692], [3023, 3080], [3747, 3880], [5809, 5866], [6145, 6262], [6574, 6657], [6935, 7032]]\n",
      "t 1.96880049058e-09\n",
      "[[187, 199], [1095, 1101], [1481, 1501], [2554, 2692], [3020, 3082], [3747, 3880], [5809, 5866], [6145, 6262], [6573, 6658], [6935, 7037]]\n",
      "t 2.08461228415e-09\n",
      "[[187, 199], [1094, 1101], [1481, 1501], [2554, 2692], [3013, 3015], [3016, 3017], [3018, 3082], [3747, 3880], [5809, 5866], [6145, 6262], [6572, 6658], [6935, 7082]]\n",
      "t 2.20042407771e-09\n",
      "[[187, 200], [1093, 1102], [1481, 1501], [2554, 2692], [3007, 3082], [3747, 3880], [5809, 5866], [6145, 6262], [6568, 6658], [6935, 7082]]\n",
      "t 2.31623587128e-09\n",
      "[[186, 200], [1092, 1102], [1481, 1501], [2554, 2692], [3006, 3082], [3747, 3880], [5809, 5866], [6145, 6262], [6566, 6659], [6935, 7082]]\n"
     ]
    }
   ],
   "source": [
    "sigma_init = np.linalg.norm(np.var(init_data[:, :3], axis=0))\n",
    "print(\"sigma_init:\", sigma_init)\n",
    "\n",
    "total_intervals = 20\n",
    "s_intervals_opt = []\n",
    "params_acc = []\n",
    "threshold_opt = []\n",
    "for i in range(1, total_intervals + 1):\n",
    "    threshold = i * sigma_init**2\n",
    "    print(\"t\", threshold)\n",
    "    print(get_static_intervals(threshold, remaining_data, 2, samples_per_second))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
