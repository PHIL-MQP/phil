{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to do the calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The first step is to let the IMU sit at rest for $T_{init}$ seconds. This interval is derived from the Allen Variance metnhod.\n",
    " - Also during this initial time interval, measure the average gyro readings in each axis: $\\textbf{b}^g$\n",
    " - Let the IMU sit at some orientation for 4 seconds, then move it to some other orientation. Repeat this between 36 and 50 times.\n",
    " - Iterate over each gyroscope readings and subtract the bias $\\text{b}^g$\n",
    " - Compute the magnitude of the variance $\\varsigma_{init}$ for the accelerometer data over the $T_{init}$. To do this, you iterate over each accelerometer reading during $T_{init}$ and compute the sample variance. This is the average of the variance for each point: $var(a) = (a-\\mathbb{E}[a])^2$. Do this for each axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick code example of this part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_value:  1.03333333333\n",
      "sample variance: 0.0322222222222\n"
     ]
    }
   ],
   "source": [
    "x = [1.1, 1.2, 0.9, 0.9, 1.3, 0.8]\n",
    "expected_value = np.mean(x)\n",
    "print(\"expected_value: \", expected_value)\n",
    "sample_variance = np.mean((x - expected_value)**2)\n",
    "print(\"sample variance:\", sample_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Iterate over a bunch of thresholds and compute how good each one is at calibrating the data. This is what the loop in Algorithm 1 refers to.\n",
    "   - Set the threshold you're testing to $threshold = i * \\varsigma_{init}$\n",
    "   - Compute the regions of static/dynamic using that threshold\n",
    "     - Iterate over each window of $t_{wait}$ size in the collected data and compute the sample variance (same as above) and compare to the threshold\n",
    "     - If it's greater, the you classify as dynamics, otherwise as static\n",
    "     - The output will be like the black line in Figure 3\n",
    "   - Do the LM optimization (magic call the Eigen).\n",
    "     - For this LM, we need to provide a functor that has `int operator()(const Eigen::VectorXf &x, Eigen::VectorXf &fvec) const` and `int df(const Eigen::VectorXf &x, Eigen::MatrixXf &fjac) const`. For `operator()` it should fill `fvec` with the values of the equation $e_k={\\lVert g\\rVert}^2 - {\\lVert T^aK^a(a_k^S+b^a)\\rVert}^2$, where ${\\lVert g\\rVert}^2 = 9.8$. For `df`, you fill `fjac` with each error term $\\frac{\\partial e_1}{\\partial \\theta^{acc}}, \\dots, \\frac{\\partial e_k}{\\partial \\theta^{acc}}$.\n",
    "      - Compute the residuals for the final optimized parameters\n",
    "      - Save (residuals, params, threshold, intervals) if they're the best ones so far\n",
    " - Calibrate the accelerometer $a^o = T^aK^a(a^S+b^a)$\n",
    " - Calibrate the gyroscope using another LM. This time in `int operator()` you fill `fvec` with $\\lVert(u_{a,k} - u_{g,k})\\rVert$ and also the partials into `fjac`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Jacobians\n",
    "\n",
    "Look in `docs/IMU_calibration.pdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the accuacy of numerical derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five-point approximations\n",
      "[[ 0.192     ]\n",
      " [-0.024     ]\n",
      " [ 0.158     ]\n",
      " [-0.04800001]\n",
      " [-1.24480035]\n",
      " [-0.0042    ]\n",
      " [-0.24      ]\n",
      " [-1.556     ]\n",
      " [-0.042     ]]\n"
     ]
    }
   ],
   "source": [
    "def func(theta_acc):\n",
    "    T = np.array([[1, -theta_acc[0], theta_acc[1]],[0, 1, -theta_acc[2]],[0,0,1]])\n",
    "    K = np.array([[theta_acc[3],0,0],[0,theta_acc[4],0],[0,0,theta_acc[5]]])\n",
    "    b = np.array([[theta_acc[6]],[theta_acc[7]],[theta_acc[8]]])\n",
    "    return 1 - np.linalg.norm(T@K@(a_i + b))**2\n",
    "\n",
    "def five_point_approximation(func, theta_acc, h):\n",
    "    N = theta_acc.shape[1]\n",
    "    partials = np.ndarray((N,1))\n",
    "    for partial_idx in range(N):\n",
    "        hs = np.array([-2*h, -h, h, 2*h])\n",
    "        nodes = np.repeat(theta_acc, 4, axis=0)\n",
    "        nodes[:,partial_idx] += hs\n",
    "        five_point_approx = 1/(12*h)*(func(nodes[0]) - 8*func(nodes[1]) + 8*func(nodes[2]) - func(nodes[3]))\n",
    "        partials[partial_idx] = five_point_approx\n",
    "    return partials\n",
    "\n",
    "\n",
    "# theta_acc = [a_yz, a_zy, a_zx, s_x_a, s_y_a, s_z_a, b_x_a, b_y_a, b_z_a]\n",
    "theta_acc = np.array([[0.1, 0, 0.1, 1, 1, 1, 0, 0.1, 0]], dtype=np.float32)\n",
    "a_i = np.array([[0.2], [0.7], [0.1]])\n",
    "h = 0.1\n",
    "\n",
    "print(\"five-point approximations\")\n",
    "print(five_point_approximation(func, theta_acc, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hs = np.array([-2*h, -h, h, 2*h])\n",
    "nodes = np.repeat(theta_acc, 4, axis=0)\n",
    "nodes[:,0] += hsReferences:\n",
    "\n",
    " - https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf\n",
    " - http://eigen.tuxfamily.org/bz_attachmentbase/attachment.cgi?id=395\n",
    " - https://medium.com/@sarvagya.vaish/levenberg-marquardt-optimization-part-1-981f5777b1d7\n",
    " - https://medium.com/@sarvagya.vaish/levenberg-marquardt-optimization-part-2-5a71f7db27a0\n",
    " - https://github.com/SarvagyaVaish/Eigen-Levenberg-Marquardt-Optimization/blob/master/main.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_filename = \"recorded_sensor_data/imu_calibration_11_14_20-00-00/imu_calibration_data_11_14.csv\"\n",
    "reader = csv.reader(open(data_filename, 'r'))\n",
    "\n",
    "next(reader) # skip header\n",
    "data = []\n",
    "for row in reader:\n",
    "    data.append([float(x) for x in row])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterate over the Tinit period to compute the gyro biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyro_biases: [ 0.0654159   0.13007117  0.08329117]\n"
     ]
    }
   ],
   "source": [
    "Tinit = 4\n",
    "samples_per_second = 100\n",
    "Tinit_idx = 4 * samples_per_second\n",
    "init_data = data[:Tinit_idx]\n",
    "gyro_biases = np.mean(init_data, axis=0)[3:6]\n",
    "print(\"gyro_biases:\", gyro_biases)\n",
    "sample_variance = np.var(init_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
