#include <aruco/aruco.h>
#include <fstream>
#include <iostream>
#include <opencv2/highgui.hpp>
#include <opencv2/imgproc.hpp>
#include <sstream>
#include <string>
#include <algorithm>
#include <map>
#include <stdexcept>

#include <phil/common/args.h>
#include <phil/common/pcdwriter.h>

// set of poses and the frames they were detected
std::map<int, cv::Mat> frame_pose_map;

void getQuaternionAndTranslationfromMatrix44(const cv::Mat &M_in,
                                             float &qx,
                                             float &qy,
                                             float &qz,
                                             float &qw,
                                             float &tx,
                                             float &ty,
                                             float &tz);

int main(int argc, const char **argv) {
  args::ArgumentParser
      parser("Calculates the location of the camera in the world from a markermap and a video stream.");
  args::HelpFlag help(parser, "help", "Display this help menu", {'h', "help"});
  args::Positional<std::string> in_video_param(parser, "in_video_filename", "input video", args::Options::Required);
  args::Positional<std::string> markermap_param
      (parser, "markermap_filename", "markermap yml file generated by the mapper_* programs", args::Options::Required);
  args::Positional<std::string>
      camera_config_param(parser, "params_filename", "camera parameters yaml file", args::Options::Required);
  args::Positional<std::string> out_pcd_param(parser,
                                              "out_pcd_filename",
                                              "writes poses of the tags and robot to this point cloud file."
                                                  " Use pcl_viewer to examine the result.",
                                              args::Options::Required);
  args::ValueFlag<float> marker_size_flag(parser, "marker_size", "size of the marker in meters", {'s', "size"});
  args::ValueFlag<std::string>
      dict_param(parser, "dictionary", "a dictionary name or dictionary file. Defaults to ARUCO", {'d', "dict"});

  try {
    parser.ParseCLI(argc, argv);
  }
  catch (args::Help &e) {
    std::cerr << parser;
    return 0;
  }
  catch (args::RequiredError &e) {
    std::cerr << parser;
    return 0;
  }

  cv::VideoCapture video_capture;
  aruco::CameraParameters cam_params;
  aruco::MarkerMap marker_map;
  aruco::MarkerDetector detector;
  aruco::MarkerMapPoseTracker pose_tracker;

  video_capture.open(args::get(in_video_param));
  if (!video_capture.isOpened()) {
    std::cerr << "Could not open video\n";
    return EXIT_FAILURE;
  }

  marker_map.readFromFile(args::get(markermap_param));

  float marker_size = args::get(marker_size_flag);

  // read first image to get the dimensions
  cv::Mat frame;
  video_capture >> frame;

  cam_params.readFromXMLFile(args::get(camera_config_param));
  cam_params.resize(frame.size());

  std::string dict_used_by_markermap = marker_map.getDictionary();
  std::string dict_name = args::get(dict_param);
  if (dict_name.empty()) {
    dict_name = "ARUCO";
  }

  if (dict_name != dict_used_by_markermap && dict_used_by_markermap != "CUSTOM") {
    std::cerr << "Warning: The markermap uses dictionary ["
              << dict_used_by_markermap
              << "] but you asked to used ["
              << dict_name
              << "].\n";
  }

  detector.setDictionary(dict_name);
  detector.setDetectionMode(aruco::DM_VIDEO_FAST);

  if (marker_map.isExpressedInPixels() && marker_size > 0) {
    marker_map = marker_map.convertToMeters(marker_size);
  }

  if (!cam_params.isValid()) {
    std::cerr << "Camera parameters are in valid\n";
    return EXIT_FAILURE;
  }

  if (marker_map.isExpressedInMeters()) {
    pose_tracker.setParams(cam_params, marker_map);
  }

  char key = 0;
  int index = 0;

  do {
    video_capture.retrieve(frame);
    index++;  // number of images captured
    std::vector<aruco::Marker> detected_markers = detector.detect(frame);
    if (pose_tracker.isValid()) {
      if (pose_tracker.estimatePose(detected_markers)) {
        frame_pose_map.insert({index, pose_tracker.getRTMatrix()});
      }
    }
  } while (video_capture.grab());

  std::string out_pcd_filname = args::get(out_pcd_param);
  savePCDFile(out_pcd_filname, marker_map, frame_pose_map);

  float qx, qy, qz, qw, tx, ty, tz;
  for (auto frame_pose_pair : frame_pose_map) {
    if (!frame_pose_pair.second.empty()) {
      getQuaternionAndTranslationfromMatrix44(frame_pose_pair.second, qx, qy, qz, qw, tx, ty, tz);
      std::cout << frame_pose_pair.first << " " << tx << " " << ty << " " << tz << " " << qx << " " << qy << " " << qz
                << " "
                << qw
                << "\n";
    }
  }
}

void getQuaternionAndTranslationfromMatrix44(const cv::Mat &M_in,
                                             float &qx,
                                             float &qy,
                                             float &qz,
                                             float &qw,
                                             float &tx,
                                             float &ty,
                                             float &tz) {

  auto SIGN = [](float x) {
    return (x >= 0.0f) ? +1.0f : -1.0f;
  };

  auto NORM = [](double a, double b, double c, double d) {
    return sqrt(a * a + b * b + c * c + d * d);
  };
  // get the 3d part of matrix and get quaternion
  assert(M_in.total() == 16);
  cv::Mat M;
  M_in.convertTo(M, CV_32F);
  // use now eigen
  float r11 = M.at<float>(0, 0);
  float r12 = M.at<float>(0, 1);
  float r13 = M.at<float>(0, 2);
  float r21 = M.at<float>(1, 0);
  float r22 = M.at<float>(1, 1);
  float r23 = M.at<float>(1, 2);
  float r31 = M.at<float>(2, 0);
  float r32 = M.at<float>(2, 1);
  float r33 = M.at<float>(2, 2);

  double q0 = (r11 + r22 + r33 + 1.0f) / 4.0f;
  double q1 = (r11 - r22 - r33 + 1.0f) / 4.0f;
  double q2 = (-r11 + r22 - r33 + 1.0f) / 4.0f;
  double q3 = (-r11 - r22 + r33 + 1.0f) / 4.0f;
  if (q0 < 0.0f) {
    q0 = 0.0f;
  }
  if (q1 < 0.0f) {
    q1 = 0.0f;
  }
  if (q2 < 0.0f) {
    q2 = 0.0f;
  }
  if (q3 < 0.0f) {
    q3 = 0.0f;
  }
  q0 = sqrt(q0);
  q1 = sqrt(q1);
  q2 = sqrt(q2);
  q3 = sqrt(q3);
  if (q0 >= q1 && q0 >= q2 && q0 >= q3) {
    q0 *= +1.0f;
    q1 *= SIGN(r32 - r23);
    q2 *= SIGN(r13 - r31);
    q3 *= SIGN(r21 - r12);
  } else if (q1 >= q0 && q1 >= q2 && q1 >= q3) {
    q0 *= SIGN(r32 - r23);
    q1 *= +1.0f;
    q2 *= SIGN(r21 + r12);
    q3 *= SIGN(r13 + r31);
  } else if (q2 >= q0 && q2 >= q1 && q2 >= q3) {
    q0 *= SIGN(r13 - r31);
    q1 *= SIGN(r21 + r12);
    q2 *= +1.0f;
    q3 *= SIGN(r32 + r23);
  } else if (q3 >= q0 && q3 >= q1 && q3 >= q2) {
    q0 *= SIGN(r21 - r12);
    q1 *= SIGN(r31 + r13);
    q2 *= SIGN(r32 + r23);
    q3 *= +1.0f;
  } else {
    std::cerr << "Coding error" << std::endl;
  }
  double r = NORM(q0, q1, q2, q3);
  qx = static_cast<float>(q0 / r);
  qy = static_cast<float>(q1 / r);
  qz = static_cast<float>(q2 / r);
  qw = static_cast<float>(q3 / r);

  tx = M.at<float>(0, 3);
  ty = M.at<float>(1, 3);
  tz = M.at<float>(2, 3);
}
